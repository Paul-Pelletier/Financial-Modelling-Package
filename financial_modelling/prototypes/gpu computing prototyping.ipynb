{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from torch import device, tensor, float32, float16, optim, no_grad, cuda, sqrt, nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NonLinearModel:\n",
    "    def __init__(self, initial_params, device_index=0):\n",
    "        if cuda.is_available():\n",
    "            self.device = device(f\"cuda:{device_index}\")\n",
    "            logging.info(f\"Using GPU: {cuda.get_device_name(device_index)}\")\n",
    "        else:\n",
    "            self.device = device(\"cpu\")\n",
    "            logging.info(\"GPU not available. Using CPU.\")\n",
    "            \n",
    "        # Convert initial_params to a 2D tensor for multiple sets\n",
    "        self.initial_params = tensor(initial_params, requires_grad=True, dtype=float32, device=self.device)\n",
    "        self.num_sets = self.initial_params.shape[0]  # Number of parameter sets\n",
    "        self.fitted_params = None\n",
    "        self.param_evolution = []  # List to store parameter evolution\n",
    "\n",
    "    def fit(self, x_train_list, y_train_list, maturities, epochs=1000, learning_rate=0.01, log_interval=50, logging = True):\n",
    "        \"\"\"\n",
    "        Fit the model to the given data using Adam optimizer with a weighted MSE loss.\n",
    "        \"\"\"\n",
    "        # Convert lists to batched tensors\n",
    "        x_train_batched = nn.utils.rnn.pad_sequence(x_train_list, batch_first=True, padding_value=0.0).to(self.device, dtype=float32)  # Shape: (num_sets, max_points)\n",
    "        y_train_batched = nn.utils.rnn.pad_sequence(y_train_list, batch_first=True, padding_value=0.0).to(self.device, dtype=float32)  # Shape: (num_sets, max_points)\n",
    "        maturities = maturities.to(self.device, dtype=float16)  # Shape: (num_sets,)\n",
    "        \n",
    "        # Mask for valid entries (to handle varying sequence lengths)\n",
    "        valid_mask = (x_train_batched != 0).float()\n",
    "\n",
    "        optimizer = optim.Adam([self.initial_params], lr=learning_rate)\n",
    "        \n",
    "        # Iterates on epochs\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute predictions for all sets simultaneously\n",
    "            y_pred_batched = self.functional_form(x_train_batched, self.initial_params, maturities)  # Shape: (num_sets, max_points)\n",
    "\n",
    "            # Compute MSE loss\n",
    "            mse_loss = ((y_pred_batched - y_train_batched) ** 2 * valid_mask).sum() / valid_mask.sum()\n",
    "\n",
    "            # Backpropagation\n",
    "            mse_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #logging\n",
    "            if logging:\n",
    "                # Log loss and parameter evolution\n",
    "                if (epoch + 1) % log_interval == 0:\n",
    "                    self.param_evolution.append(self.initial_params.detach().cpu().numpy().copy())\n",
    "                    logging.info(f\"Epoch {epoch + 1}/{epochs}, Total Weighted Loss: {mse_loss.item():.4f}\")\n",
    "\n",
    "        self.fitted_params = self.initial_params.detach().cpu().numpy()\n",
    "        logging.info(\"Model fitting complete.\")\n",
    "        return self.fitted_params\n",
    "\n",
    "    def plot_param_evolution(self):\n",
    "        \"\"\"\n",
    "        Plot the evolution of parameters during training.\n",
    "        \"\"\"\n",
    "        num_epochs = len(self.param_evolution)\n",
    "        param_evolution_array = np.array(self.param_evolution)  # Shape: (num_epochs, num_sets, num_params)\n",
    "\n",
    "        fig, axes = plt.subplots(self.num_sets, 1, figsize=(8, 4 * self.num_sets))\n",
    "        if self.num_sets == 1:\n",
    "            axes = [axes]  # Ensure axes is iterable when there's only one parameter set\n",
    "\n",
    "        for i in range(self.num_sets):\n",
    "            for param_idx in range(self.initial_params.shape[1]):  # Iterate over parameters\n",
    "                axes[i].plot(\n",
    "                    range(1, num_epochs + 1),\n",
    "                    param_evolution_array[:, i, param_idx],\n",
    "                    label=f\"Param {param_idx + 1}\",\n",
    "                )\n",
    "            axes[i].set_title(f\"Parameter Set {i + 1}\")\n",
    "            axes[i].set_xlabel(\"Epoch\")\n",
    "            axes[i].set_ylabel(\"Parameter Value\")\n",
    "            axes[i].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, x_test_list, maturities):\n",
    "        \"\"\"\n",
    "        Predict output for the given input data.\n",
    "        \"\"\"\n",
    "        maturities = maturities.to(self.device, dtype=float32)\n",
    "        predictions = []\n",
    "        with no_grad():\n",
    "            for i in range(self.num_sets):\n",
    "                x_test = x_test_list[i].to(self.device, dtype=float32)\n",
    "\n",
    "                # Compute prediction\n",
    "                y_pred = self.functional_form(\n",
    "                    x_test.unsqueeze(0), self.initial_params[i].unsqueeze(0), maturities[i].unsqueeze(0)\n",
    "                )[0]\n",
    "                predictions.append(y_pred.cpu())\n",
    "        return predictions\n",
    "\n",
    "    def plot_results(self, x_train_list, y_train_list, y_pred_list, num_sets_to_plot=5):\n",
    "        \"\"\"\n",
    "        Plot the training data vs. fitted model predictions.\n",
    "        \"\"\"\n",
    "        num_sets_to_plot = min(num_sets_to_plot, self.num_sets)\n",
    "        fig, axes = plt.subplots(num_sets_to_plot, 1, figsize=(8, 4 * num_sets_to_plot))\n",
    "        if num_sets_to_plot == 1:\n",
    "            axes = [axes]  # Ensure axes is iterable when num_sets_to_plot is 1\n",
    "\n",
    "        for i in range(num_sets_to_plot):\n",
    "            x_train = x_train_list[i].cpu().numpy()\n",
    "            y_train = y_train_list[i].cpu().numpy()\n",
    "            y_pred = y_pred_list[i].cpu().numpy()\n",
    "\n",
    "            axes[i].plot(x_train, y_train, label=\"Training Data\", marker=\"o\", linestyle=\"None\")\n",
    "            axes[i].plot(x_train, y_pred, label=\"Fitted Model\", linestyle=\"-\")\n",
    "            axes[i].set_title(f\"Parameter Set {i + 1}\")\n",
    "            axes[i].set_xlabel(\"x\")\n",
    "            axes[i].set_ylabel(\"y\")\n",
    "            axes[i].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def functional_form(x_batched, params_batched, maturities_batched):\n",
    "        \"\"\"\n",
    "        Generic functional form for any number of parameters.\n",
    "        \"\"\"\n",
    "        batch_size, num_points = x_batched.shape\n",
    "        num_params = params_batched.shape[1]\n",
    "\n",
    "        # Generic computation\n",
    "        delta = x_batched - params_batched[:, 3:4]  # Assuming param 3 is 'm'\n",
    "        total_variance = params_batched[:, 0:1] + params_batched[:, 1:2] * (\n",
    "            params_batched[:, 2:3] * delta + sqrt(delta**2 + params_batched[:, 4:5]**2)\n",
    "        )\n",
    "        return sqrt(total_variance) / sqrt(maturities_batched[:, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A non liear class that inmplements a non linear model (the Stochastic Volatility Insipired parametrization).\n",
    "\n",
    "The methods implemented are:\n",
    "- Constructor :\n",
    "--The inital parameters (for the fitting process) are converted to leaf tensors (i.e. tensors that not need to have operations tracked). The argument needed is 'requires_grad=True'\n",
    "\n",
    "- Fit method: Fits the model on the give data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_37160\\232480672.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.initial_params = tensor(initial_params, requires_grad=True, dtype=float32, device=self.device)\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "amount_of_data = 20  # Number of parameter sets\n",
    "x_train_list = [tensor(np.linspace(-0.2, 0.2, 50 * (i + 1)), dtype=float16) for i in range(amount_of_data)]\n",
    "maturities = tensor([i + 1 for i in range(amount_of_data)], dtype=float16)\n",
    "\n",
    "# Generate y_train_list\n",
    "y_train_list = [\n",
    "    NonLinearModel.functional_form(\n",
    "        x.unsqueeze(0),\n",
    "        tensor([0.04 + np.random.random() / 10,\n",
    "                0.1 + np.random.random() / 10,\n",
    "                -0.3 + np.random.random() / 10,\n",
    "                0.0 + np.random.random() / 10,\n",
    "                0.2 + np.random.random() / 10], dtype=float32).unsqueeze(0),\n",
    "        maturities[i].unsqueeze(0)\n",
    "    )[0]\n",
    "    for i, x in enumerate(x_train_list)\n",
    "]\n",
    "\n",
    "initial_params = np.array([[0.04, 0.1, -0.3, 0.0, 0.2] for _ in range(amount_of_data)])\n",
    "initial_params = tensor(initial_params, dtype=float32)\n",
    "\n",
    "# Initialize Model\n",
    "model = NonLinearModel(initial_params)\n",
    "\n",
    "# Fit Model\n",
    "fitted_params = model.fit(x_train_list, y_train_list, maturities, epochs=400, log_interval=50)\n",
    "\n",
    "# Predict and Plot Results\n",
    "y_pred_list = model.predict(x_train_list, maturities)\n",
    "#model.plot_results(x_train_list, y_train_list, y_pred_list, num_sets_to_plot=amount_of_data)\n",
    "\n",
    "# Plot Parameter Evolution\n",
    "#model.plot_param_evolution()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
